{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RubriCheck Complete Pipeline\n",
        "============================\n",
        "Integrates all three modules:\n",
        "1. Essay Preprocessor (essay_preprocessor.ipynb)\n",
        "2. Rubric Parser (rubric_parser_prompt.ipynb) \n",
        "3. Grading Engine (grading_engine.ipynb)\n",
        "\n",
        "## Usage:\n",
        "- **Command Line**: `python rubriCheck_pipeline.py --rubric path/to/rubric.pdf --essay path/to/essay.txt`\n",
        "- **Programmatic**: Use the `RubriCheckPipeline` class in your code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "from dataclasses import asdict\n",
        "\n",
        "\n",
        "# Add current directory to path for imports (Jupyter notebook compatible)\n",
        "import os\n",
        "current_dir = os.getcwd()\n",
        "if current_dir not in sys.path:\n",
        "    sys.path.append(current_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ API key is set and ready to use!\n",
            "🔑 Key starts with: sk-proj-...\n",
            "✅ API key is set and ready to use!\n",
            "🔑 Key starts with: sk-proj-...\n",
            "✅ All modules imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import all three modules\n",
        "try:\n",
        "    # Import from essay_preprocessor.py\n",
        "    from essay_preprocessor import EssayPreprocessor, PreprocessOptions, ProcessedEssay\n",
        "    \n",
        "    # Import from rubric_parser_prompt.py  \n",
        "    from rubric_parser_prompt import parse_rubric_file, demo_parse_rubric\n",
        "    \n",
        "    # Import from grading_engine.py\n",
        "    from grading_engine import grade_essay, GradeSummary\n",
        "    \n",
        "    print(\"✅ All modules imported successfully!\")\n",
        "    \n",
        "except ImportError as e:\n",
        "    print(f\"❌ Import error: {e}\")\n",
        "    print(\"Make sure all three Python modules are in the same directory\")\n",
        "    print(\"Available files:\")\n",
        "    import os\n",
        "    for f in os.listdir('.'):\n",
        "        if f.endswith('.py'):\n",
        "            print(f\"  - {f}\")\n",
        "    sys.exit(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RubriCheckPipeline Class\n",
        "The main pipeline class that integrates all three modules.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RubriCheckPipeline:\n",
        "    \"\"\"\n",
        "    Complete pipeline that integrates all three RubriCheck modules.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, api_key_file: str = r\"C:\\Users\\Leo\\AI projects\\_api.txt\"):\n",
        "        \"\"\"Initialize the pipeline with API key configuration.\"\"\"\n",
        "        self.api_key_file = api_key_file\n",
        "        self._setup_api_key()\n",
        "        \n",
        "    def _setup_api_key(self):\n",
        "        \"\"\"Set up API key from file.\"\"\"\n",
        "        try:\n",
        "            with open(self.api_key_file, 'r', encoding='utf-8') as f:\n",
        "                for line in f:\n",
        "                    if line.strip().startswith('rubriCheck:'):\n",
        "                        api_key = line.strip().split(':', 1)[1].strip()\n",
        "                        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "                        print(\"✅ API key loaded successfully\")\n",
        "                        return\n",
        "            raise ValueError(\"rubriCheck API key not found in file\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"❌ API file not found at {self.api_key_file}\")\n",
        "            sys.exit(1)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error loading API key: {e}\")\n",
        "            sys.exit(1)\n",
        "    \n",
        "    def process_essay(self, essay_path: str, options: Optional[PreprocessOptions] = None) -> ProcessedEssay:\n",
        "        \"\"\"Step 1: Process essay using essay_preprocessor module.\"\"\"\n",
        "        print(f\"📝 Processing essay: {essay_path}\")\n",
        "        \n",
        "        if not os.path.exists(essay_path):\n",
        "            raise FileNotFoundError(f\"Essay file not found: {essay_path}\")\n",
        "            \n",
        "        with open(essay_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "            essay_text = f.read()\n",
        "        \n",
        "        preprocessor = EssayPreprocessor()\n",
        "        options = options or PreprocessOptions()\n",
        "        processed_essay = preprocessor.run(essay_text, options)\n",
        "        \n",
        "        print(f\"✅ Essay processed: {len(processed_essay.paragraphs)} paragraphs, {processed_essay.metadata.word_count} words\")\n",
        "        return processed_essay\n",
        "    \n",
        "    def parse_rubric(self, rubric_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Step 2: Parse rubric using rubric_parser_prompt module.\"\"\"\n",
        "        print(f\"📋 Parsing rubric: {rubric_path}\")\n",
        "        \n",
        "        if not os.path.exists(rubric_path):\n",
        "            raise FileNotFoundError(f\"Rubric file not found: {rubric_path}\")\n",
        "        \n",
        "        rubric = demo_parse_rubric(rubric_path)\n",
        "        \n",
        "        if not rubric:\n",
        "            raise ValueError(\"Failed to parse rubric\")\n",
        "            \n",
        "        print(f\"✅ Rubric parsed: {len(rubric.get('criteria', []))} criteria\")\n",
        "        return rubric\n",
        "    \n",
        "    def grade_essay(self, rubric: Dict[str, Any], processed_essay: ProcessedEssay, \n",
        "                  max_span_chars: int = 240) -> GradeSummary:\n",
        "        \"\"\"Step 3: Grade essay using grading_engine module.\"\"\"\n",
        "        print(\"🤖 Grading essay with AI...\")\n",
        "        \n",
        "        essay_paragraphs = [p.text for p in processed_essay.paragraphs if p.text.strip()]\n",
        "        converted_rubric = self._convert_rubric_format(rubric)\n",
        "        summary = grade_essay(converted_rubric, essay_paragraphs, max_span_chars)\n",
        "        \n",
        "        print(f\"✅ Grading complete: {summary.numeric_score} ({summary.letter})\")\n",
        "        return summary\n",
        "    \n",
        "    def _convert_rubric_format(self, rubric: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Convert rubric from parser format to grader format.\"\"\"\n",
        "        converted = {\n",
        "            \"criteria\": [],\n",
        "            \"grading\": {\n",
        "                \"numeric\": True,\n",
        "                \"letter_bands\": [\n",
        "                    {\"min\": 90, \"max\": 100, \"letter\": \"A+\"},\n",
        "                    {\"min\": 85, \"max\": 89.99, \"letter\": \"A\"},\n",
        "                    {\"min\": 80, \"max\": 84.99, \"letter\": \"A-\"},\n",
        "                    {\"min\": 0, \"max\": 79.99, \"letter\": \"B or below\"}\n",
        "                ],\n",
        "                \"categorical_points_map\": {\"Excellent\": 4, \"Good\": 3, \"Fair\": 2, \"Poor\": 1}\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        for i, criterion in enumerate(rubric.get('criteria', [])):\n",
        "            converted_criterion = {\n",
        "                \"id\": f\"criterion_{i}\",\n",
        "                \"name\": criterion.get('name', f'Criterion {i+1}'),\n",
        "                \"descriptors\": criterion.get('descriptor_by_level', {}),\n",
        "                \"valid_levels\": rubric.get('scale', {}).get('levels', ['Excellent', 'Good', 'Fair', 'Poor']),\n",
        "                \"weight\": criterion.get('weight', 1.0) / sum(c.get('weight', 1.0) for c in rubric.get('criteria', [])),\n",
        "                \"level_scale_note\": \" → \".join(rubric.get('scale', {}).get('levels', []))\n",
        "            }\n",
        "            converted[\"criteria\"].append(converted_criterion)\n",
        "        \n",
        "        return converted\n",
        "    \n",
        "    def run_complete_pipeline(self, rubric_path: str, essay_path: str, \n",
        "                            output_path: Optional[str] = None,\n",
        "                            essay_options: Optional[PreprocessOptions] = None) -> Dict[str, Any]:\n",
        "        \"\"\"Run the complete pipeline: essay preprocessing → rubric parsing → AI grading.\"\"\"\n",
        "        print(\"🚀 Starting RubriCheck Complete Pipeline\")\n",
        "        print(\"=\" * 50)\n",
        "        \n",
        "        try:\n",
        "            # Step 1: Process essay\n",
        "            processed_essay = self.process_essay(essay_path, essay_options)\n",
        "            \n",
        "            # Step 2: Parse rubric\n",
        "            rubric = self.parse_rubric(rubric_path)\n",
        "            \n",
        "            # Step 3: Grade essay\n",
        "            grade_summary = self.grade_essay(rubric, processed_essay)\n",
        "            \n",
        "            # Compile results\n",
        "            results = {\n",
        "                \"pipeline_info\": {\n",
        "                    \"rubric_file\": rubric_path,\n",
        "                    \"essay_file\": essay_path,\n",
        "                    \"timestamp\": str(Path().cwd()),\n",
        "                    \"version\": \"1.0\"\n",
        "                },\n",
        "                \"essay_metadata\": asdict(processed_essay.metadata),\n",
        "                \"rubric_info\": {\n",
        "                    \"title\": rubric.get('title'),\n",
        "                    \"scale_type\": rubric.get('scale', {}).get('type'),\n",
        "                    \"criteria_count\": len(rubric.get('criteria', [])),\n",
        "                    \"source_parse\": rubric.get('source_parse', {})\n",
        "                },\n",
        "                \"grading_results\": {\n",
        "                    \"per_criterion\": [asdict(r) for r in grade_summary.per_criterion],\n",
        "                    \"numeric_score\": grade_summary.numeric_score,\n",
        "                    \"letter_grade\": grade_summary.letter,\n",
        "                    \"categorical_points\": grade_summary.categorical_points,\n",
        "                    \"reliability_flags\": grade_summary.notes\n",
        "                },\n",
        "                \"warnings\": processed_essay.warnings + rubric.get('source_parse', {}).get('warnings', [])\n",
        "            }\n",
        "            \n",
        "            # Save results if output path provided\n",
        "            if output_path:\n",
        "                with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(results, f, indent=2, ensure_ascii=False)\n",
        "                print(f\"💾 Results saved to: {output_path}\")\n",
        "            \n",
        "            print(\"\\n🎉 Pipeline completed successfully!\")\n",
        "            return results\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Pipeline failed: {e}\")\n",
        "            raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: Essay Processing\n",
        "Process essays using the essay_preprocessor module.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This method is now part of the RubriCheckPipeline class above\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: Rubric Parsing\n",
        "Parse rubrics using the rubric_parser_prompt module.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This method is now part of the RubriCheckPipeline class above\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: AI Grading\n",
        "Grade essays using the grading_engine module.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This method is now part of the RubriCheckPipeline class above\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Helper Methods\n",
        "Utility methods for the pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This method is now part of the RubriCheckPipeline class above\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Complete Pipeline\n",
        "Run the complete pipeline: essay preprocessing → rubric parsing → AI grading.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This method is now part of the RubriCheckPipeline class above\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Usage Examples\n",
        "\n",
        "### Example 1: Basic Pipeline Usage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔬 Example: Basic Pipeline Usage\n",
            "========================================\n",
            "✅ API key loaded successfully\n",
            "🚀 Starting RubriCheck Complete Pipeline\n",
            "==================================================\n",
            "📝 Processing essay: test_essay.txt\n",
            "✅ Essay processed: 3 paragraphs, 53 words\n",
            "📋 Parsing rubric: test_file/test_rubric.docx\n",
            "✅ Rubric parsed successfully!\n",
            "📊 Found 6 criteria\n",
            "📏 Scale type: categorical\n",
            "✅ Rubric parsed: 6 criteria\n",
            "🤖 Grading essay with AI...\n",
            "✅ Grading complete: 85.0 (None)\n",
            "💾 Results saved to: example_results.json\n",
            "\n",
            "🎉 Pipeline completed successfully!\n",
            "\n",
            "📊 Results:\n",
            "Score: 85.0 (None)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'pipeline_info': {'rubric_file': 'test_file/test_rubric.docx',\n",
              "  'essay_file': 'test_essay.txt',\n",
              "  'timestamp': 'c:\\\\Users\\\\Leo\\\\AI projects\\\\RubriCheck\\\\Scripts',\n",
              "  'version': '1.0'},\n",
              " 'essay_metadata': {'word_count': 53,\n",
              "  'sentence_count': 3,\n",
              "  'paragraph_count': 3,\n",
              "  'character_count': 446,\n",
              "  'language_detected': 'en',\n",
              "  'readability': {'flesch_reading_ease': 8.529748427672956,\n",
              "   'flesch_kincaid_grade': 16.458490566037742,\n",
              "   'gunning_fog': None,\n",
              "   'ari': None,\n",
              "   'coleman_liau': None},\n",
              "  'quote_ratio': 0.0,\n",
              "  'section_count': 0,\n",
              "  'chunk_count': 1},\n",
              " 'rubric_info': {'title': None,\n",
              "  'scale_type': 'categorical',\n",
              "  'criteria_count': 6,\n",
              "  'source_parse': {'method': 'narrative', 'confidence': 1.0, 'warnings': []}},\n",
              " 'grading_results': {'per_criterion': [{'criterion_id': 'criterion_0',\n",
              "    'valid_levels': ['Excellent', 'Good', 'Fair', 'Poor'],\n",
              "    'level': 'Good',\n",
              "    'justification': 'The essay presents a clear thesis regarding the importance of renewable energy to national security. While the focus is mostly maintained, there are moments where the discussion could be more tightly aligned with the thesis.',\n",
              "    'evidence_spans': [{'paragraph_index': 0,\n",
              "      'quote': 'This essay argues that renewable energy is essential to national security by reducing dependence on volatile fuel markets.'}],\n",
              "    'actionable_suggestion': 'Ensure that all arguments directly support the thesis to maintain a tighter focus throughout the essay.',\n",
              "    'refuse': False,\n",
              "    'reason': '',\n",
              "    'low_confidence': False,\n",
              "    'consistency_explanation': \"The chosen level 'Good' aligns well with the descriptor language. The justification states that the essay presents a clear thesis and mostly maintains focus, which corresponds to the descriptor for 'Good'. The evidence span supports the thesis clearly, indicating that the essay meets the expectations for this level.\",\n",
              "    'agreement_flag': 'ok',\n",
              "    'tie_break_used': False},\n",
              "   {'criterion_id': 'criterion_1',\n",
              "    'valid_levels': ['Excellent', 'Good', 'Fair', 'Poor'],\n",
              "    'level': 'Good',\n",
              "    'justification': 'The essay presents a mostly logical structure with a clear argument about renewable energy and national security. However, some transitions between points could be clearer.',\n",
              "    'evidence_spans': [{'paragraph_index': 0,\n",
              "      'quote': 'This essay argues that renewable energy is essential to national security by reducing dependence on volatile fuel markets.'},\n",
              "     {'paragraph_index': 1,\n",
              "      'quote': 'Several reports show countries with higher renewable portfolios experience less price shock; however, grid stability challenges remain.'},\n",
              "     {'paragraph_index': 2,\n",
              "      'quote': 'Opponents claim costs are prohibitive; this essay demonstrates recent cost curves and policy mechanisms that offset initial investment.'}],\n",
              "    'actionable_suggestion': 'Improve transitions between paragraphs to enhance the flow of ideas.',\n",
              "    'refuse': False,\n",
              "    'reason': '',\n",
              "    'low_confidence': False,\n",
              "    'consistency_explanation': \"The chosen level 'Good' aligns well with the descriptor language. The justification states that the essay has a mostly logical structure and presents a clear argument, which corresponds to the 'Good' descriptor. Additionally, the mention of unclear transitions supports the assessment that while the structure is mostly logical, it is not excellent, thus fitting the 'Good' level appropriately.\",\n",
              "    'agreement_flag': 'ok',\n",
              "    'tie_break_used': False},\n",
              "   {'criterion_id': 'criterion_2',\n",
              "    'valid_levels': ['Excellent', 'Good', 'Fair', 'Poor'],\n",
              "    'level': 'Good',\n",
              "    'justification': \"The essay provides good evidence regarding renewable energy's impact on national security and cost considerations. However, some evidence could be more directly tied to the main argument.\",\n",
              "    'evidence_spans': [{'paragraph_index': 1,\n",
              "      'quote': 'Several reports show countries with higher renewable portfolios experience less price shock; however, grid stability challenges remain.'},\n",
              "     {'paragraph_index': 2,\n",
              "      'quote': 'this essay demonstrates recent cost curves and policy mechanisms that offset initial investment.'}],\n",
              "    'actionable_suggestion': 'Include more specific examples or data that directly link renewable energy to national security benefits.',\n",
              "    'refuse': False,\n",
              "    'reason': '',\n",
              "    'low_confidence': False,\n",
              "    'consistency_explanation': \"The chosen level 'Good' aligns well with the descriptor language, as the justification notes that the essay provides good evidence regarding renewable energy's impact, which is mostly relevant. The evidence spans provided support this assessment, showing relevant information but indicating that some evidence could be more directly tied to the main argument, which is consistent with the 'Good' descriptor.\",\n",
              "    'agreement_flag': 'ok',\n",
              "    'tie_break_used': False},\n",
              "   {'criterion_id': 'criterion_3',\n",
              "    'valid_levels': ['Excellent', 'Good', 'Fair', 'Poor'],\n",
              "    'level': 'Good',\n",
              "    'justification': 'The essay provides some analysis regarding the impact of renewable energy on national security and cost considerations, but it primarily explains the evidence without delving deeply into implications or broader contexts.',\n",
              "    'evidence_spans': [{'paragraph_index': 0,\n",
              "      'quote': 'This essay argues that renewable energy is essential to national security by reducing dependence on volatile fuel markets.'},\n",
              "     {'paragraph_index': 1,\n",
              "      'quote': 'Several reports show countries with higher renewable portfolios experience less price shock; however, grid stability challenges remain.'},\n",
              "     {'paragraph_index': 2,\n",
              "      'quote': 'this essay demonstrates recent cost curves and policy mechanisms that offset initial investment.'}],\n",
              "    'actionable_suggestion': 'Incorporate deeper analysis of the implications of renewable energy on national security and address potential counterarguments more thoroughly.',\n",
              "    'refuse': False,\n",
              "    'reason': '',\n",
              "    'low_confidence': False,\n",
              "    'consistency_explanation': \"The chosen level 'Good' aligns well with the descriptor language. The justification states that the essay provides some analysis regarding renewable energy's impact on national security and cost considerations, which matches the descriptor's emphasis on 'some analysis' while also noting that it 'mostly explains evidence.' The evidence spans provided support this assessment, as they show instances of analysis related to national security and cost, but do not indicate a deep exploration of broader implications, consistent with the 'Good' descriptor.\",\n",
              "    'agreement_flag': 'ok',\n",
              "    'tie_break_used': False},\n",
              "   {'criterion_id': 'criterion_4',\n",
              "    'valid_levels': ['Excellent', 'Good', 'Fair', 'Poor'],\n",
              "    'level': 'Good',\n",
              "    'justification': 'The writing is generally clear and conveys the main arguments effectively, though there are minor awkwardnesses in phrasing that could be improved for better clarity.',\n",
              "    'evidence_spans': [{'paragraph_index': 0,\n",
              "      'quote': 'This essay argues that renewable energy is essential to national security by reducing dependence on volatile fuel markets.'},\n",
              "     {'paragraph_index': 1,\n",
              "      'quote': 'Several reports show countries with higher renewable portfolios experience less price shock; however, grid stability challenges remain.'}],\n",
              "    'actionable_suggestion': 'Revise sentences for conciseness to enhance clarity and engagement.',\n",
              "    'refuse': False,\n",
              "    'reason': '',\n",
              "    'low_confidence': False,\n",
              "    'consistency_explanation': \"The chosen level 'Good' aligns well with the descriptor language, as the justification notes that the writing is generally clear and effectively conveys main arguments, which matches the descriptor's mention of 'Generally clear; minor awkwardness.' The evidence spans provided support this assessment, showing clarity in the main points while acknowledging minor phrasing issues.\",\n",
              "    'agreement_flag': 'ok',\n",
              "    'tie_break_used': False},\n",
              "   {'criterion_id': 'criterion_5',\n",
              "    'valid_levels': ['Excellent', 'Good', 'Fair', 'Poor'],\n",
              "    'level': 'Good',\n",
              "    'justification': 'The essay contains few minor errors that do not affect understanding. The grammar and mechanics are mostly correct, allowing the reader to grasp the arguments presented without confusion.',\n",
              "    'evidence_spans': [{'paragraph_index': 0,\n",
              "      'quote': 'This essay argues that renewable energy is essential to national security by reducing dependence on volatile fuel markets.'},\n",
              "     {'paragraph_index': 1,\n",
              "      'quote': 'Several reports show countries with higher renewable portfolios experience less price shock; however, grid stability challenges remain.'},\n",
              "     {'paragraph_index': 2,\n",
              "      'quote': 'Opponents claim costs are prohibitive; this essay demonstrates recent cost curves and policy mechanisms that offset initial investment.'}],\n",
              "    'actionable_suggestion': 'Proofread the essay to correct any minor grammatical errors and ensure consistent punctuation throughout.',\n",
              "    'refuse': False,\n",
              "    'reason': '',\n",
              "    'low_confidence': False,\n",
              "    'consistency_explanation': \"The chosen level 'Good' aligns well with the descriptor language, as the justification states that the essay contains few minor errors that do not affect understanding. This matches the descriptor for 'Good,' which indicates that while there are some errors, they do not impede comprehension. The evidence spans provided support this assessment, showing that the content is coherent and the arguments are clear despite minor issues.\",\n",
              "    'agreement_flag': 'ok',\n",
              "    'tie_break_used': False}],\n",
              "  'numeric_score': 85.0,\n",
              "  'letter_grade': None,\n",
              "  'categorical_points': None,\n",
              "  'reliability_flags': {'any_refusals': False,\n",
              "   'any_low_confidence': False,\n",
              "   'any_needs_review': False}},\n",
              " 'warnings': []}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 1: Basic Pipeline Usage\n",
        "def example_basic_usage():\n",
        "    \"\"\"Basic example of using the pipeline.\"\"\"\n",
        "    print(\"🔬 Example: Basic Pipeline Usage\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # Initialize pipeline\n",
        "    pipeline = RubriCheckPipeline()\n",
        "    \n",
        "    # Example file paths (adjust these to your actual files)\n",
        "    rubric_path = \"test_file/test_rubric.docx\"\n",
        "    essay_path = \"test_essay.txt\"  # You'll need to create this\n",
        "    \n",
        "    # Create a sample essay if it doesn't exist\n",
        "    if not os.path.exists(essay_path):\n",
        "        sample_essay = \"\"\"\n",
        "        This essay argues that renewable energy is essential to national security by reducing dependence on volatile fuel markets.\n",
        "        \n",
        "        Several reports show countries with higher renewable portfolios experience less price shock; however, grid stability challenges remain.\n",
        "        \n",
        "        Opponents claim costs are prohibitive; this essay demonstrates recent cost curves and policy mechanisms that offset initial investment.\n",
        "        \"\"\"\n",
        "        with open(essay_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(sample_essay)\n",
        "        print(f\"📝 Created sample essay: {essay_path}\")\n",
        "    \n",
        "    try:\n",
        "        # Run complete pipeline\n",
        "        results = pipeline.run_complete_pipeline(\n",
        "            rubric_path=rubric_path,\n",
        "            essay_path=essay_path,\n",
        "            output_path=\"example_results.json\"\n",
        "        )\n",
        "        \n",
        "        # Print results\n",
        "        print(\"\\n📊 Results:\")\n",
        "        grading = results[\"grading_results\"]\n",
        "        print(f\"Score: {grading['numeric_score']} ({grading['letter_grade']})\")\n",
        "        \n",
        "        return results\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# Run the basic example\n",
        "example_basic_usage()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 2: Step-by-Step Execution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Example: Step-by-Step Execution\n",
            "===================================\n",
            "✅ API key loaded successfully\n",
            "Step 1: Processing essay...\n",
            "📝 Processing essay: test_essay.txt\n",
            "✅ Essay processed: 3 paragraphs, 53 words\n",
            "   - 3 paragraphs\n",
            "   - 53 words\n",
            "   - Language: en\n",
            "\n",
            "Step 2: Parsing rubric...\n",
            "📋 Parsing rubric: test_file/test_rubric.docx\n",
            "✅ Rubric parsed successfully!\n",
            "📊 Found 6 criteria\n",
            "📏 Scale type: categorical\n",
            "✅ Rubric parsed: 6 criteria\n",
            "   - 6 criteria\n",
            "   - Scale type: categorical\n",
            "\n",
            "Step 3: Grading essay...\n",
            "🤖 Grading essay with AI...\n",
            "✅ Grading complete: 85.0 (None)\n",
            "   - Score: 85.0\n",
            "   - Letter: None\n",
            "   - Criteria evaluated: 6\n",
            "\n",
            "📋 Detailed Results:\n",
            "   1. criterion_0: Good\n",
            "      Justification: The essay presents a clear thesis regarding the importance of renewable energy f...\n",
            "   2. criterion_1: Good\n",
            "      Justification: The essay has a mostly logical structure, presenting arguments for renewable ene...\n",
            "   3. criterion_2: Good\n",
            "      Justification: The essay provides good evidence regarding the benefits of renewable energy, par...\n",
            "   4. criterion_3: Good\n",
            "      Justification: The essay provides some analysis, particularly in discussing the benefits of ren...\n",
            "   5. criterion_4: Good\n",
            "      Justification: The writing is generally clear but contains minor awkwardness, particularly in t...\n",
            "   6. criterion_5: Good\n",
            "      Justification: The essay contains few minor errors that do not affect understanding. The gramma...\n"
          ]
        }
      ],
      "source": [
        "# Example 2: Step-by-Step Execution\n",
        "def example_step_by_step():\n",
        "    \"\"\"Example showing step-by-step pipeline execution.\"\"\"\n",
        "    print(\"🔍 Example: Step-by-Step Execution\")\n",
        "    print(\"=\" * 35)\n",
        "    \n",
        "    pipeline = RubriCheckPipeline()\n",
        "    \n",
        "    try:\n",
        "        # Step 1: Process essay\n",
        "        print(\"Step 1: Processing essay...\")\n",
        "        processed_essay = pipeline.process_essay(\"test_essay.txt\")\n",
        "        print(f\"   - {len(processed_essay.paragraphs)} paragraphs\")\n",
        "        print(f\"   - {processed_essay.metadata.word_count} words\")\n",
        "        print(f\"   - Language: {processed_essay.metadata.language_detected}\")\n",
        "        \n",
        "        # Step 2: Parse rubric\n",
        "        print(\"\\nStep 2: Parsing rubric...\")\n",
        "        rubric = pipeline.parse_rubric(\"test_file/test_rubric.docx\")\n",
        "        print(f\"   - {len(rubric.get('criteria', []))} criteria\")\n",
        "        print(f\"   - Scale type: {rubric.get('scale', {}).get('type')}\")\n",
        "        \n",
        "        # Step 3: Grade essay\n",
        "        print(\"\\nStep 3: Grading essay...\")\n",
        "        grade_summary = pipeline.grade_essay(rubric, processed_essay)\n",
        "        print(f\"   - Score: {grade_summary.numeric_score}\")\n",
        "        print(f\"   - Letter: {grade_summary.letter}\")\n",
        "        print(f\"   - Criteria evaluated: {len(grade_summary.per_criterion)}\")\n",
        "        \n",
        "        # Show detailed results\n",
        "        print(\"\\n📋 Detailed Results:\")\n",
        "        for i, criterion in enumerate(grade_summary.per_criterion, 1):\n",
        "            print(f\"   {i}. {criterion.criterion_id}: {criterion.level}\")\n",
        "            if criterion.justification:\n",
        "                print(f\"      Justification: {criterion.justification[:80]}...\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "\n",
        "# Run the step-by-step example\n",
        "example_step_by_step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook provides the complete RubriCheck pipeline that integrates all three modules:\n",
        "\n",
        "1. **Essay Preprocessor** (`essay_preprocessor.ipynb`) - Processes and structures student essays\n",
        "2. **Rubric Parser** (`rubric_parser_prompt.ipynb`) - Extracts and parses rubric documents  \n",
        "3. **Grading Engine** (`grading_engine.ipynb`) - Grades essays using AI against rubrics\n",
        "\n",
        "### Key Features:\n",
        "- **Complete Integration**: All three modules work together seamlessly\n",
        "- **Flexible Usage**: Can run complete pipeline or individual steps\n",
        "- **Multiple Formats**: Supports various file formats (PDF, DOCX, TXT, images)\n",
        "- **Comprehensive Results**: Detailed grading with justifications and suggestions\n",
        "- **Error Handling**: Robust error handling and informative messages\n",
        "\n",
        "### Usage:\n",
        "- **Programmatic**: Use the `RubriCheckPipeline` class in your code\n",
        "- **Interactive**: Run individual cells to test specific functionality\n",
        "- **Examples**: Uncomment the example functions to see the pipeline in action\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
